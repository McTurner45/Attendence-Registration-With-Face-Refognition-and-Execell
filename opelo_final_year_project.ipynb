{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "opelo final year project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMO9WFjGHHhxGTRTmBmS2LR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/McTurner45/Attendence-Registration-With-Face-Refognition-and-Execell/blob/main/opelo_final_year_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xIV2bcW0nVS"
      },
      "source": [
        "pip install Dlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5wOeuLu0IRd"
      },
      "source": [
        "pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V14VNebBzIOT"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import os\n",
        "from datetime import datetime"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhMpsluJzICw"
      },
      "source": [
        "path='/content/ImagesAttendence'\n",
        "images=[]\n",
        "classNames=[]\n",
        "myList=os.listdir(path)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJa63DQ21lcc"
      },
      "source": [
        "for cl in myList:\n",
        "  currImag=cv2.imread(f'{path}/{cl}')\n",
        "  images.append(currImag)\n",
        "  classNames.append(os.path.splitext(cl)[0])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1b5ZyNx2j6n"
      },
      "source": [
        "def findEncodings(images):\n",
        "  encodingList=[]\n",
        "  for img in images:\n",
        "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    encode= face_recognition.face_encodings(img)[0]\n",
        "    encodingList.append(encode)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2UtPZzT3b1_"
      },
      "source": [
        "encodeListKnown=findEncodings(images)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUH6CQ9C9QeS"
      },
      "source": [
        "def markAttendence(name):\n",
        "  with open('/content/Attendence.csv') as f:\n",
        "    myDataList = f.readlines()\n",
        "    nameList=[]\n",
        "    for line in myDataList:\n",
        "      entry=line.split(,)\n",
        "      nameList.append(entry[0])\n",
        "\n",
        "    if name not in nameList:\n",
        "      now= datetime.now()\n",
        "      dtString= now.strftime('%H:%M:%S')\n",
        "      f.writelines(f'\\n{name},{dtString}')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjV2uXD-3mu9"
      },
      "source": [
        "cap=cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "  success, img = cap.read()\n",
        "  imgS= cv2.resize(img,(0,0),None,0.25,0.25)\n",
        "  imgS=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "  facesCurFrame=face_recognition.face_locations(imgS)\n",
        "  encodeCurFrame= face_recognition.face_encodings(imgS,facesCurFrame)\n",
        "\n",
        "  for encodeFace,faceLoc in zip(encodeCurFrame,facesCurFrame):\n",
        "    matches=face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
        "    faceDis=face_recognition.face_distance(encodeListKnown,encodeFace)\n",
        "    matchIndex= np.argmin(faceDis)\n",
        "\n",
        "    if matches[matchIndex]:\n",
        "      name= classNames[matchIndex].upper()\n",
        "\n",
        "      y1,x2,y2,x1= faceLoc\n",
        "\n",
        "      y1,x2,y2,x1=y1*4,x2*4,y2*4,x1*4\n",
        "\n",
        "      cv2.ractangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "      cv2.ractangle(img,(x1,y2-55),(x2,y2),(0,255,0),cv2.FILLED)\n",
        "      cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
        "\n",
        "      markAttendence(name)\n",
        "\n",
        "  cv2.imshow('Webcam',img)\n",
        "  cv2.waitKey(1)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k040inCY6w4B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}